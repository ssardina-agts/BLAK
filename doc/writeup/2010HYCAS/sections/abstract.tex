An important drawback to the popular Belief, Desire, and Intentions (BDI)
paradigm is that such systems include no element of learning from experience.
% %
%In particular, the so-called \emph{context conditions} of plans, on which the
%whole model relies for plan selection, are restricted to be boolean
%formulas that are to be specified at design/implementation time.
% %
We describe a novel BDI execution framework that models
context conditions as \emph{decision trees}, rather than boolean
formulae, allowing
agents to \emph{learn} the probability of success for plans based on
experience. By using a probabilistic plan selection function, the
agents can balance exploration and exploitation of their plans.
% %
We extend earlier work to include both parameterised goals and
recursion and modify our previous approach to decision tree
confidence to include large and even non-finite domains that arise
from such consideration.
% %
Our evaluation on a pre-existing program that relies heavily
on recursion and parametrised goals confirms previous results
that naive learning fails in some circumstances, and
demonstrates that the improved approach learns relatively well.

