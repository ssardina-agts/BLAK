An important drawback to the popular Belief, Desire, and Intentions (BDI)
paradigm is that such systems include no element of learning from experience.
% %
%In particular, the so-called \emph{context conditions} of plans, on which the
%whole model relies for plan selection, are restricted to be boolean
%formulas that are to be specified at design/implementation time.
% %
We describe a novel BDI execution framework that models
context conditions as \emph{decision trees}, rather than boolean
formulae, allowing
agents to \emph{learn} the probability of success for plans based on
experience. By using a probabilistic plan selection function, the
agents can balance exploration and exploitation of their plans.
% %
We extend earlier work to include both parameterised goals and
recursion. We also modify our previous approach to decision tree
confidence to deal with the large and even non-finite domain arising
from recursion and parameterised goals. 
% %
We evaluate our approach on a pre-existing program that relies heavily
on recursion and parametrised goals, confirming previous results
showing that naive learning fails in some circumstances, and
demonstrating that our approach learns relatively well.

