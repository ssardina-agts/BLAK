\input{figs/fig-experiments}
%!TEX root = ../aamas11storage.tex
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Results}\label{sec:results}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section, we show experiments that demonstrate the suitability of the framework developed in Section~\ref{sec:framework} using the energy domain example of Section~\ref{sec:application}. In particular, we report on three experiments that highlight the adaptive behaviour of the controller under different situations in which the environment dynamics are changing. 
%%
The first experiment shows how the agent recovers functionality against standard deterioration in module capacities. In the second one, the agent is exposed to partial (temporal) failures of the system caused by modules malfunctioning, but which do not completely preclude the battery from successfully resolving system requests. Lastly, in the third experiment, we analyse the controller response and learning behaviour in the extreme case where the system suffers complete failure for some time and is thereafter restored.

%% provided now by package SIunits
% \newcommand{\kilo}{\!\operatorname{k}}


\subsubsection{Experimentation Setup}

The following experimental setup applies to all experiments. 
%%
We conducted experiments for a battery system with \emph{five} modules (i.e., $k=5$). For each module, the current charge state is described by a discrete value in the range $[0:3]$, where zero indicates a fully discharged state and three indicates a fully charged state. In addition, each module has an assigned configuration for the current period from the set $\{+c, 0, -c\}$, where $c=1/k$. The operational model is simple: charging is meant to add $+c$ while discharging is meant to add $-c$ to a module's charge state, otherwise the state is unchanged for the period (i.e., there is no charge loss).
%%
Thus, the desired overall battery response is in the (normalized) range $[-1.0:+1.0]$ in discrete intervals of $\pm c$. 
%%
The complete state space for the problem is described by the number of modules ($5$), the possible requests ($11$), the charge state of the system ($4^5$), and the assigned configuration of the system ($3^5$), that is, $5 \times 11 \times 4^5 \times 3^5 \approx 13.7$ million states. Though significant, note that the agent does not have to learn over this space, because the filtering of nonsensical configurations by the plans' context conditions $\psi_i$ will reduce substantially it.




At the beginning of each learning episode, the configuration of each module is reset to $0$ (i.e., not in used). 
%%
The charge state of each module, however, is left untouched and carries over from the previous episode, as it would be the case in the actual deployed system. This has implications for learning, particularly that the state space is \emph{not} sampled uniformly. %%
Each episode corresponds to one $G(r,5,s)$ goal-event request: achieve overall battery response of $r$ under current module charge states $s$.  For simplicity of analysis, we assume only satisfiable requests: a solution always exists. The outcome of each episode is either no response (no configuration was executed), or a single invocation of the $\pExecute$ plan for operating (and evaluating) the battery.  The tolerance level is set to $0$, so that the battery response is deemed successful only when the sum of the module configurations matches the request exactly.

An important thing we used is an \emph{applicability threshold} for plan selection of $40\%$, meaning that plans with a likelihood of success below this value are discarded from consideration. While such feature does not alter the overal learning performance of the battery controller, it does preclude the battery to being operated (i.e., plan $\pExecute$) under module configurations that are bound to be unsuccessful. In fact, we found that the threshold used reduces the number of battery operations by $12\%$, which is substantial when considering battery life. Again, we stress that the difference in performance without the applicability threshold is not significant.


The threshold for stability calculation is set to $0.5$. We used an averaging window of $n=5$ for both the stability-based metric $\C_s(\cdot,\cdot,n)$ and the world-based metric $\C_d(\cdot,n)$, and a (balanced) weighting of $\alpha=0.5$ for the final confidence measure $\C(\cdot,\cdot,\cdot)$.
%%
Finally, each experiment is run five times and the reported results are averages from these runs.



\subsubsection{Experiment 1: Capacity Deterioration}

In this experiment we model the (typical) situation where module capacities deteriorate over time. In a real system this will happen gradually over several years of typical use. However, to show the response to substantial change, we force this deterioration to occur instantaneously in this experiment. 
%%
Figure \ref{fig:experiment1} shows the results for this case. In the beginning of the experiment, the system performs ideally as programmed, and goes about recording its experiences although there is no evident use of the resulting learning yet. After some time (about $5\kilo$ episodes), the capacity of all five modules drops instantaneously, from the initial range $[0:3]$) to range $[0:2]$. 
%%
These capacity changes result in a rapid drop in performance corresponding to the set of programmed/learnt solutions that no longer work. The ideally programmed system would, at this point, converge to $\approx 76\%$ performance. The learning system, however, aptly rectifies the situation by learning to avoid most module configurations that no longer work. 


%\begin{figure}[t]
%\begin{center}
%\input{figs/fig-experiment1}
%\end{center}
%\caption{Adapting to capacity deterioration.}
%\label{fig:experiment1}
%\end{figure}


\subsubsection{Experiment 2: Partial Failure with Restoration}

In this scenario, we model a series of module malfunctions and their subsequent restoration. However, the battery always remains capable of successfully responding to the request.
%%
In the experiment, the first battery module fails for the duration $[0:20\kilo]$ after which it is reinstated, the second module fails for the period $[20\kilo:40\kilo]$, and so on. 
%%
Figure \ref{fig:experiment2} shows the system performance for this stetting. At the beginning of each change, namely, at $0\kilo$ and and $20\kilo$, the performance drops dramatically, as the expected solutions that utilise the failed module no longer work.\footnote{The apparent difference between the  performance drop at $0\kilo$ and $20\kilo$ is not meaningful in any way; it just happens that more ``bad'' cases occurred in the  first failure. The theoretical drop in performance is $45\%$.} 
%%
Following each module failure, the system successfully learns to operate the battery without it, by always configuring the failed module to not-in-use (i.e., state $0$). Importantly, by the time each failed module is restored (e.g., iteration $20\kilo$ for the first module), the system has already learnt to operate without it, and hence, will not try to re-use it unless really required.


%\begin{figure}[t]
%\begin{center}
%\input{figs/fig-experiment2}
%\end{center}
%\caption{Adapting to module failures/restorations over time.}
%\label{fig:experiment2}
%\end{figure}

\subsubsection{Experiment 3: Complete Failure with Restoration}

In this experiment, we model the extreme scenario of complete failure of the system for some time followed by full restoration. 
%%
Technically, \emph{all} module configurations would fail for the period $[0:5\kilo]$, the failed modules are restored to normal operation.  
%%
The results are shown in Figure~\ref{fig:experiment3}. 
%%
At the beginning of the experiment, overall performance drops to zero rapidly, as all of the ideal configurations start are unsuccessful to respond to the request. After a while (at around $2\kilo$ episodes), the estimated likelihood of success of all plans drops below the applicability threshold of $40\%$. At this point, the battery operation comes to a complete halt: no plans are ever applicable and plan $\pExecute$ is never invoked. 
%%
Them, at episode $5\kilo$, the failed modules are repaired so that the battery is restored to normal operation. However, observe that since no plans is ever tried due to applicability threshold, then new learning may not occur. To tackle this issue, the applicability threshold we used as a ``soft'' applicability threshold mechanism: the $40\%$ threshold applies $90\%$ of the time. This allows the battery to operate with some likelihood and the agent system to eventually start recovering at around $6\kilo$ episodes.\footnote{Note that the battery will be actually operated after five module configuration plans $\pSet$ have been selected and carried out (one per existing module). In the best case, only one of these plans has failed the threshold and hence there is a $10\%$ chance that the battery will operate. On the other hand, if all plans are failing the applicability threshold, then there is only a $0.1^5$ (i.e.,  $0.00001$) chance that the battery will operate. In a real system, the agent should have some input from the environment indicating that some important changes have ocurred (e.g., some batteries have been replaced/repaired).}




%\begin{figure}[t]
%\begin{center}
%\input{figs/fig-experiment3}
%\end{center}
%\caption{Adapting to system restoration after complete failure.}
%\label{fig:experiment3}
%\end{figure}

\medskip
To recap, we have described in this section three type of experiments for the energy storage domain that demonstrate, empirically, that the BDI learning framework is able to adapt to changes in the dynamics of the environment when the confidence metric developed in Section~\ref{sec:confidence} is used.  



 

