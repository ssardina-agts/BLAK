%!TEX root = ../aamas11storage.tex
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}\label{sec:discussion}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In no particular order:

We show how to combine context conditions with decision trees as suggested in earlier work.

We show how our dynamic confidence measure is better able to cope with the practical issue that learning is not a one-shot affair. Learning must be un-learnt and re-learnt as required. Together with a means of limiting the training data, the measure could be used to build systems that learn ad infinitum.

We focus on an important programming problem: programming for adaptability. The aim is to build fully-functional systems that are also adaptable enough to withstand (some) environmental changes in the future. 

We make a start at understanding what it means to keep-on-learning. We show that for certain problems there may be a strong case for filtering training data (also important when learning ad infinitum). We see $75\%$ reduction in training set size for no noticeable change in performance in our experiments. This is promising and motivates further investigation on the matter. More general filtering techniques are required and a better handle on the sorts of problems where this makes sense.


Minor: We quantify the benefit of applicability thresholds in the application.



