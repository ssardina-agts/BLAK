=====================================================================
REVIEWER 1
=====================================================================

Lower stability threshold implies greater accuracy (more samples) and
vice-versa; while small variations do not seem to impact learning, a deeper
analysis is required. Stability is assessed every time a leaf-plan terminates a
trace.

The world state includes parameters relevant for the goal and plan (including
descendants). This can be programmer specified, or calculated from variables
accessed.

Selective learning is a great suggestion (thanks!); while we have not done that
yet, it is definitively possible.

Learning does not impact reactivity; the main overhead is in rebuilding decision
trees: here an incremental approach would help.

Automated planning requires a (non-changing) model of the world's dynamics,
which we do not have here.

Regarding environment dynamics: difference from traditional learning is that the
learning task is not stationary.


=====================================================================
REVIEWER 2
=====================================================================

Good point: indeed our hierarchical learning shares similarities with
Diettrich's MAXQ approach that forseeably could replace the decision-tree
framework. Note, however, our focus has been the principled integration of
learning with BDI, and less on the learning technique.

We shall explain the "plan selection process" clearer as well as discuss impact
of parameters' values on learning: for stability threshold, see answer to
Review1; regarding \alpha, it is generally  not critical to performance if there
are many decision paths in the hierarchy and many states in which plans apply.

The BDI execution process is unchanged: standard plan selection is simply
replaced by the decision tree and probabilistic selection.

Regarding states: programmed context conditions constrain 13.7M states to
roughly 1.5M.
=====================================================================


=====================================================================
REVIEWER 3
=====================================================================

Stability states how well-informed decisions were. Given all decision paths,
success is rare and failure frequent. Upon success, we consider the decisions
well-informed (stability/degree=1); but upon failures, we want to know how
well-informed (degree=?). For threshold please read response to reviewer1.

Programmed context conditions are used as the first filter followed by learning
filter to decide final applicability. Interpret "real" context conditions to
mean the sum result of this filtering.

RecordDegreeStability "saves" d wrt P1,W1 so is not required to be passed on
recursively.

Plans for G(r,5,s) configure all modules by: configuring module5 then posting
and waiting for G(r,4,s') to finish. "Possible requests" and "overall response"
both mean [-1.0:+1.0] in steps +/-c.

We agree that use of terms "BDI" and "dynamics" could be improved.


=====================================================================
EOF
=====================================================================
