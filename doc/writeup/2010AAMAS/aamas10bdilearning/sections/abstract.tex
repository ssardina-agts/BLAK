An important drawback to the popular Belief, Desire, and Intentions (BDI)
paradigm is that such systems include no element of learning from experience.
% %
In particular, the so-called \emph{context conditions} of plans, in which the
whole model relies for plan selection, are restricted to be boolean formulas that
are to be specified at design/implementation time.
% %
To address these limitations, we propose a novel BDI programming framework that,
by suitably modeling context conditions as \emph{decision trees}, it allows
agents to \emph{learn} the probability of success for plans based on previous
execution experiences. By using a probabilistic plan selection function, the
agents can balance exploration and exploitation of their plans.
% %
We develop and empirically investigate two extreme approaches to learning the new
context conditions and showed that both can be advantageous in certain
situations.
% %
Finally, we propose a generalization of the probabilistic plan selection function
that will yield a middle-ground between the two extreme approaches, and which we
thus argue is the most flexible and simple one.

