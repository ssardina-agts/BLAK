{
    int num = 0;
    double mass;
    int POWER = 1;
    Signature thandler = null;
    double pMax = -1.0;
    int pMaxId;
    boolean isReposted = false;
    Vector alternatives = new Vector();

    if (pc.failure.size() > 0) {
	/* This is a re-posted goal */
	ag.env.writeLog("MetaPlan: Choosing for reposted event " + pc.event.getEventName());
	isReposted = true;
    }

    for (Signature s = pc.applicable.first(); s != null; s = pc.applicable.next(s)) {
        if (s.getInfo() instanceof PlanIdInfo) {
	    PlanIdInfo info = (PlanIdInfo) s.getInfo();
	    if (info.isFailedThresholdHandler) {
		thandler = s;
		/* In failure recovery mode, a new leanring episode is started only when 
		 * all options have been exhausted. So if we are in failure recovery mode 
		 * AND the only applicable plan is the dummy plan AND we are handling
		 * the top goal THEN we are ready to initiate a new leanring episode.
		 */
		if ((ag.run_mode == RunMode.FAILURE_RECOVERY) && (pc.applicable.size() == 1) && (ag.planNodes[info.plan_id].topGoal() != null)) {
		    ag.setTriggerNewIteration(true);
		    ag.env.writeLog("MetaPlan: Exhausted failure recovery at top level. Will trigger new iteration.");
		}
	    } else {
		alternatives.add(ag.planNodes[info.plan_id]);
		double p = info.pSuccess;
		if (ag.env.plan_selection == PlanSelectMode.COVERAGE) {
		    p = 0.5 + (Math.pow(info.coverage, 1/info.coverageWeight) * (p - 0.5));
		    String str =
		    "Plan " + ag.planNodes[info.plan_id].name() +
		    " REVISED the probability in state " + ag.planNodes[info.plan_id].stringOfLastState() +
		    " to p=" + ((double) ((int) (p * 10000))) / 10000 +
		    " based on coverage c=" + ((double) ((int) (info.coverage * 10000))) / 10000 +
		    "^" + ((double) ((int) ((1/info.coverageWeight) * 10000))) / 10000;
		    ag.env.writeLog(str);
		} else if (ag.env.plan_selection == PlanSelectMode.CONFIDENCE) {
		    double c = (info.planConfidence * ag.confidenceAlpha) + (info.stateConfidence * (1.0-ag.confidenceAlpha));
		    p = 0.5 + (Math.pow(c, 1/info.coverageWeight) * (p - 0.5));
		    String str =
		    "Plan " + ag.planNodes[info.plan_id].name() +
		    " REVISED the probability in state " + ag.planNodes[info.plan_id].stringOfLastState() +
		    " to p=" + ((double) ((int) (p * 10000))) / 10000 +
		    " based on confidence c=" + ((double) ((int) (c * 10000))) / 10000 +
		    "^" + ((double) ((int) ((1/info.coverageWeight) * 10000))) / 10000 +
                    ". (pConf="+((double) ((int) (info.planConfidence * 10000))) / 10000 +
		    " sConf="+((double) ((int) (info.stateConfidence * 10000))) / 10000 +
		    " alpha="+ag.confidenceAlpha+")";
		    ag.env.writeLog(str);
		}
		if (p < 0.0001) {
		    mass += 0.0001;
		} else {
		    mass += Math.pow(p, POWER);
		}
		if (p > pMax) {
		    pMax = p;
		    pMaxId = info.plan_id;
		}
	    }
	}
	num++;
    }

    /* If pMax is less than the threshold and not a leaf plan then always select the failed threshold handler plan */
    if ((pMax < ag.planSelectThreshold) && (thandler != null) && !ag.planNodes[pMaxId].isLeaf() ) {
	    pc.chosen = thandler;
	    ag.env.writeLog("MetaPlan: Using failed threshold plan since " +
		"p("+(((double) ((int) (pMax * 10000))) / 10000)+")<threshold("+
		(((double) ((int) (ag.planSelectThreshold * 10000))) / 10000)+")");
    } else {
	if (num > 0) {
	    double[] prob = new double[num];
	    double acc = 0;
	    int i;
	    String str = "";
	    for (Signature s = pc.applicable.first(); s != null; s = pc.applicable.next(s), i++) {
		if (s.getInfo() instanceof PlanIdInfo) {
		    PlanIdInfo info = (PlanIdInfo) s.getInfo();
		    if (!info.isFailedThresholdHandler) {
		    	str = "MetaPlan: At iteration " + ag.env.it +
			    ", the probability for plan at index " + i + " ";
			double p = info.pSuccess;
			if (ag.env.plan_selection == PlanSelectMode.COVERAGE) {
			    p = 0.5 + (Math.pow(info.coverage, 1/info.coverageWeight) * (p - 0.5));
			} else if (ag.env.plan_selection == PlanSelectMode.CONFIDENCE) {
			    double c = (info.planConfidence * ag.confidenceAlpha) + (info.stateConfidence * (1.0-ag.confidenceAlpha));
			    p = 0.5 + (Math.pow(c, 1/info.coverageWeight) * (p - 0.5));
			}
			str += "(" + ag.planNodes[info.plan_id].name() + ") for state " +
			    ag.planNodes[info.plan_id].stringOfLastState() + " is ";
			if (p < 0.0001) {
			    str += "0.0001/" + mass;
			    acc += 0.0001 / mass;
			} else {
			    str += p + "^" + POWER + "/" + mass;
			    acc += Math.pow(p, POWER) / mass;
			}
			prob[i] = acc;
		    }
		} else {
		    str += "(unknown) is 1.0/" + num;
		    prob[i] = 1.0 / num;
		}
		ag.env.writeLog(str);
	    }
	    double rnd = ag.generator.nextDouble();
	    int choice = 0;
	    while (prob[choice] < rnd) {
		choice++;
	    }
	    str = "[";
	    for (i = 0; i < num; i++) {
		str += " " + ((double) ((int) (prob[i] * 10000))) / 10000;
	    }
	    str += " ]";
	    ag.env.writeLog("MetaPlan: Choosing from applicable plans with cumulative probabilities " +
			    str + ". Chosen plan index " + choice);
	    Signature s = pc.applicable.first();
	    for (i = 0; i < choice; i++) {
		s = pc.applicable.next(s);
	    }
	    pc.chosen = s;
	}
        PlanIdInfo info = (PlanIdInfo) pc.chosen.getInfo();
	if(isReposted) {
	    /* Handling reposted goal, so force all parent nodes in the active trace 
	     * to record failure, regardless of the actual result.
	     */
	    ag.activeExecutionTrace.setShouldRecordFailure(isReposted);
	    ag.env.writeLog("MetaPlan: Plan "+ag.planNodes[info.plan_id].name()+" is handling reposted goal, so will record failure for all parents in: "+ag.activeExecutionTrace);
	}
	ag.activeExecutionTrace.pushTrace(ag.planNodes[info.plan_id].parent(),ag.planNodes[info.plan_id],alternatives,ag.state());
	ag.env.writeLog("MetaPlan: Added Plan "+ag.planNodes[info.plan_id].name()+" to the active execution trace: "+ag.activeExecutionTrace);
    }
}
