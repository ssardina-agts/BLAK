import agents.Config.PlanSelectMode;

public plan MetaPlan extends Plan {
    #chooses for event SolveDisc;
	#handles event PlanChoice pc;
	#uses interface Player ag;

	static boolean relevant(PlanChoice pc){
		return true;
	}

	context(){
		true;
	}

	#reasoning method
	body(){
        int num = 0;
        double mass;
        int POWER = 1;
        Signature thandler = null;
        double pMax = -1.0;
        int pMaxId;
        boolean fullConfidence = false;
        if (ag.pselect() == PlanSelectMode.CONFIDENCE) {
            for (Signature s = pc.applicable.first(); s != null; s = pc.applicable.next(s)) {
                if (s.getInfo() instanceof PlanIdInfo) {
                    PlanIdInfo info = (PlanIdInfo) s.getInfo();
                    if ((info.confidence == 1.0) && (info.pSuccess > 0.95)) {
                        fullConfidence = true;
                        if (ag.learningMode()) {
                            ag.writeLog("Metaplan: Using full confidence c=1.0");
                        }
                        break;
                    }
                }
            }
        }
        
        for (Signature s = pc.applicable.first(); s != null; s = pc.applicable.next(s)) {
            if (s.getInfo() instanceof PlanIdInfo) {
                PlanIdInfo info = (PlanIdInfo) s.getInfo();
                double p = info.pSuccess;
                if ((ag.pselect() == PlanSelectMode.CONFIDENCE) && !fullConfidence) {
                    p = 0.5 + (info.confidence * (p - 0.5));
                    String str =
                        "MetaPlan: P" + info.plan_id +
                        " REVISED probability" +
                        " to p=" + ((double) ((int) (p * 10000))) / 10000 +
                        " based on confidence c=" + ((double) ((int) (info.confidence * 10000))) / 10000;
                    if (ag.learningMode()) {
                        ag.writeLog(str);
                    }
                }
                if (p < 0.0001) {
                    mass += 0.0001;
                } else {
                    mass += Math.pow(p, POWER);
                }
                if (p > pMax) {
                    pMax = p;
                    pMaxId = info.plan_id;
                }
            }
            num++;
        }

        if (num > 0) {
            double[] prob = new double[num];
            double acc = 0;
            int i;
            for (Signature s = pc.applicable.first(); s != null; s = pc.applicable.next(s), i++) {
                if (s.getInfo() instanceof PlanIdInfo) {
                    PlanIdInfo info = (PlanIdInfo) s.getInfo();
                    double p = info.pSuccess;
                    if ((ag.pselect() == PlanSelectMode.CONFIDENCE) && !fullConfidence) {
                        p = 0.5 + (info.confidence * (p - 0.5));
                    }
                    if (p < 0.0001) {
                        acc += 0.0001 / mass;
                    } else {
                        acc += Math.pow(p, POWER) / mass;
                    }
                    prob[i] = acc;
                } else {
                    prob[i] = 1.0 / num;
                }
            }
            double rnd = ag.selector().nextDouble();
            int choice = 0;
            while (prob[choice] < rnd) {
                choice++;
            }
            String str = "[";
            for (i = 0; i < num; i++) {
                str += " " + ((double) ((int) (prob[i] * 10000))) / 10000;
            }
            str += " ]";
            if (ag.learningMode()) {
                ag.writeLog("MetaPlan: Choosing from applicable plans with cumulative probabilities " +
                    str + ". Chosen plan index " + choice);
            }
            Signature s = pc.applicable.first();
            for (i = 0; i < choice; i++) {
                s = pc.applicable.next(s);
            }
            pc.chosen = s;
        }
	}
}
